{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, path, image_size):\n",
    "\n",
    "        self.path = path\n",
    "        self.image_size = image_size\n",
    "\n",
    "        self.images = None\n",
    "\n",
    "    def create_images_data(self):\n",
    "\n",
    "        data = np.load(self.path)\n",
    "\n",
    "        for i in range(data.shape[0]):\n",
    "\n",
    "            data[i] = (data[i]+1.0)*0.5\n",
    "            data[i] = data[i]*255.0\n",
    "\n",
    "        data = data.astype('uint8')\n",
    "\n",
    "        images = []\n",
    "\n",
    "        for image in data:\n",
    "\n",
    "            image = Image.fromarray(image)\n",
    "            image = image.resize(self.image_size)\n",
    "            array = np.array(image)\n",
    "            image.close()\n",
    "            images.append(array)\n",
    "\n",
    "        images = np.array(images)\n",
    "        images = np.stack(images, 0)\n",
    "        images = images.astype('float32')\n",
    "        \n",
    "        for i in range(images.shape[0]):\n",
    "\n",
    "            images[i] = images[i]/127.5 - 1.0\n",
    "\n",
    "        images = torch.from_numpy(images)\n",
    "        self.images = images.view(images.size(0), images.size(3), images.size(1), images.size(2))\n",
    "\n",
    "        del images\n",
    "\n",
    "        print(f\"Images data created with size {self.images.size()} and ready to go!\")\n",
    "\n",
    "    def load_images_data(self, numpy=True):\n",
    "\n",
    "        if numpy:\n",
    "\n",
    "            images = np.load(self.path)\n",
    "            images = images.astype('float32')\n",
    "        \n",
    "            for i in range(images.shape[0]):\n",
    "\n",
    "                images[i] = images[i]/127.5 - 1.0\n",
    "\n",
    "            images = torch.from_numpy(images)\n",
    "            self.images = images.view(images.size(0), images.size(3), images.size(1), images.size(2))\n",
    "\n",
    "            del images\n",
    "\n",
    "            print(f\"Images data loaded with size {self.images.size()} and ready to go!\")\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            self.images = torch.load(self.path)\n",
    "\n",
    "            print(f\"Images data loaded with size {self.images.size()} and ready to go!\")\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return self.images[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset('D:/Python/Projects/filtered_images.npy', (8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images data created with size torch.Size([6854, 3, 8, 8]) and ready to go!\n"
     ]
    }
   ],
   "source": [
    "data.create_images_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transconv2out(input, kernel, stride, padding):\n",
    "    x = (input-1)*stride\n",
    "    y = 2*padding\n",
    "    z = 1*(kernel-1)\n",
    "\n",
    "    output = x - y + z + 1\n",
    "    return output\n",
    "\n",
    "def conv2out(input, kernel, stride, padding):\n",
    "    x = 2*padding\n",
    "    y = 1*(kernel-1)\n",
    "    z = (input + x - y - 1)/stride\n",
    "\n",
    "    output = z + 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, ):\n",
    "\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        #self.transconv1 = nn.ConvTranspose2d(100, 3, 4, 1, 0, bias=False)\n",
    "\n",
    "        # For level 2(generating 8x8 images):\n",
    "        self.transconv1 = nn.ConvTranspose2d(100, 50, 4, 1, 0, bias=False)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(50)\n",
    "        self.transconv2 = nn.ConvTranspose2d(50, 3, 4, 2, 1, bias=False)\n",
    "        # And so forth...\n",
    "        \n",
    "        self.PRelu = nn.PReLU()\n",
    "        self.tanh = nn.Tanh() # Since our images are between -1 and 1. Consider removing if having problems with vanishing gradients.\n",
    "    \n",
    "    # Note: Consider adding LSTMs ----> Check Prototype.py ----> Let's abandon LSTMs in order to prioritize Attention layers...if I can manage to make one.\n",
    "    # NoteÂ²: Consider using LeakyReLU 0.2 just like NVidia did...or a PReLU like it's done in SRGAN\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Level 1 ---> 1 transconv only\n",
    "        x = self.transconv1(input)\n",
    "        #output = self.tanh(x)\n",
    "        # Level 2\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.PRelu(x)\n",
    "        x = self.transconv2(x)\n",
    "        output = self.tanh(x)\n",
    "        # And so on...\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = Generator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(net, level):\n",
    "\n",
    "    for n, p in net.named_parameters():\n",
    "\n",
    "        if 'conv' and str(level) in n:\n",
    "\n",
    "            nn.init.normal_(p, 0, 0.02)\n",
    "\n",
    "        elif 'batchnorm' and 'weight' and str(level) in n:\n",
    "            nn.init.normal_(p, 1, 0.02)\n",
    "\n",
    "        elif 'batchnorm' and 'bias' and str(level) in n:\n",
    "            nn.init.constant_(p, 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_init(netG, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (transconv1): ConvTranspose2d(100, 50, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "  (batchnorm1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (PRelu): PReLU(num_parameters=1)\n",
      "  (transconv2): ConvTranspose2d(50, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (tanh): Tanh()\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1             [-1, 50, 4, 4]          80,000\n",
      "       BatchNorm2d-2             [-1, 50, 4, 4]             100\n",
      "             PReLU-3             [-1, 50, 4, 4]               1\n",
      "   ConvTranspose2d-4              [-1, 3, 8, 8]           2,400\n",
      "              Tanh-5              [-1, 3, 8, 8]               0\n",
      "================================================================\n",
      "Total params: 82,501\n",
      "Trainable params: 82,501\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 0.31\n",
      "Estimated Total Size (MB): 0.34\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print the model\n",
    "print(netG)\n",
    "summary(netG, (100, 1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        #self.conv1 = nn.Conv2d(3, 1, 4, 1, 0, bias=False)\n",
    "        # Level 2:\n",
    "        self.conv1 = nn.Conv2d(3, 100, 3, 1, 1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(100, 1, 4, 1, 0, bias=False)\n",
    "        # And so on\n",
    "        '''self.batchnorm2 = nn.BatchNorm2d(ndf * 2)\n",
    "        self.conv3 = nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(ndf * 4)\n",
    "        self.conv4 = nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(ndf * 8)\n",
    "        self.conv5 = nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False)'''\n",
    "        #self.sigmoid = nn.Sigmoid() ---> Included in BCEWithLogits (in log version)\n",
    "\n",
    "        self.pool2x2 = nn.AvgPool2d(2, 2)\n",
    "        self.LRelu = nn.LeakyReLU(0.2)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        # Level 1 ---> Conv\n",
    "        #x = self.conv1(input)\n",
    "        # Level 2:\n",
    "        x = self.conv1(input)\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool2x2(x)\n",
    "        x = self.LRelu(x)\n",
    "        x = self.conv2(x)\n",
    "        # Further and further\n",
    "        '''#x = torch.randn(x.size()).to(device) + x\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.LeakyRelu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv3(x)\n",
    "        #x = torch.randn(x.size()).to(device) + x\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.LeakyRelu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv4(x)\n",
    "        #x = torch.randn(x.size()).to(device) + x\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.LeakyRelu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv5(x)'''\n",
    "        output = x\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "netD = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_init(netD, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (conv1): Conv2d(3, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (conv2): Conv2d(100, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "  (pool2x2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (LRelu): LeakyReLU(negative_slope=0.2)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 100, 8, 8]           2,700\n",
      "           Dropout-2            [-1, 100, 8, 8]               0\n",
      "         AvgPool2d-3            [-1, 100, 4, 4]               0\n",
      "         LeakyReLU-4            [-1, 100, 4, 4]               0\n",
      "            Conv2d-5              [-1, 1, 1, 1]           1,600\n",
      "================================================================\n",
      "Total params: 4,300\n",
      "Trainable params: 4,300\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.12\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 0.14\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print the model\n",
    "print(netD)\n",
    "summary(netD, (3, 8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From level 2 and beyond: load weights from previous level into new Generator. Manipulating the tensor shape is necessary.\n",
    "\n",
    "previous_models = torch.load('Saves/default_Cocogoat.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_generator = previous_models['generator_params']\n",
    "previous_discriminator = previous_models['discriminator_params']\n",
    "\n",
    "current_generator = netG.state_dict()\n",
    "current_discriminator = netD.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transconv1.weight\n",
      "conv1.weight\n"
     ]
    }
   ],
   "source": [
    "for layer in previous_generator.keys():\n",
    "    print(layer)\n",
    "\n",
    "for layer in previous_discriminator.keys():\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 48, 4, 4])\n",
      "torch.Size([100, 50, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "# From level 2 and beyond: load weights from previous level into new Generator. Manipulating the tensor shape is necessary.\n",
    "\n",
    "previous_generator = previous_models['generator_params']\n",
    "previous_discriminator = previous_models['discriminator_params']\n",
    "\n",
    "#print(previous_generator['transconv1.weight'].size()) # (100, 3, 4, 4)\n",
    "#print(current_generator['transconv1.weight'].size()) # (100, 50, 4, 4)\n",
    "\n",
    "weights = previous_generator['transconv1.weight']\n",
    "\n",
    "weights = torch.cat([weights]*16, dim=1)\n",
    "\n",
    "print(weights.size()) # (100, 3, 4, 4)\n",
    "\n",
    "zeros = torch.zeros(weights.size(0), 2, weights.size(2), weights.size(3)).to(device)\n",
    "weights = torch.cat((weights, zeros), dim=1)\n",
    "print(weights.size()) # (100, 50, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 3, 4, 4])\n",
      "torch.Size([100, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Applying weights from previous level. Again, just for visualization. The real thing will happen inside the training function.\n",
    "\n",
    "#print(previous_discriminator['conv1.weight'].size()) # (1, 3, 4, 4)\n",
    "#print(current_discriminator['conv1.weight'].size()) # (100, 3, 3, 3)\n",
    "\n",
    "desired_shape = current_discriminator['conv1.weight'].size()\n",
    "previous_shape = previous_discriminator['conv1.weight'].size()\n",
    "\n",
    "weights = previous_discriminator['conv1.weight']\n",
    "\n",
    "weights = torch.cat([weights]*100, 0)\n",
    "\n",
    "print(weights.size()) # (100,3,4,4)\n",
    "\n",
    "upsampler = torch.nn.Upsample((3,3))\n",
    "weights = upsampler(weights)\n",
    "print(weights.size()) # (30, 3, 6, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish convention for real and fake labels during training --> Using 0.9 and 0. instead of 1 and 0 ---> One-sided label smoothing\n",
    "# https://arxiv.org/pdf/1606.03498.pdf\n",
    "real_label = 0.9 \n",
    "fake_label = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Adam optimizers for both G and D ---> NVidia Progressive Grow: Same optimizer parameters with Adam - lr = 0.001, b1 = 0, b2 = 0.99\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=1e-3, betas=(0, 0.99)) # Consider changing learning rate or even the optimizer\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=1e-3, betas=(0, 0.99)) # If learning rate is too aggressive --> might fail to converge or might collapse\n",
    "\n",
    "# Setting up schedulers - Maybe it's better if we use the same decay and steps for both generator and discriminator\n",
    "schedulerD = optim.lr_scheduler.StepLR(optimizerD, 10000, gamma=0.1)\n",
    "schedulerG = optim.lr_scheduler.StepLR(optimizerG, 10000, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to keep track of progress\n",
    "\n",
    "costsD = []\n",
    "costsG = []\n",
    "#content_losses = [] # I really liked the idea in SRGAN of using content loss. We could use something like this to improve diversity somehow.\n",
    "#adversarial_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(model_name=None, generator=netG, discriminator=netD):\n",
    "\n",
    "    previous_models = torch.load(f'Saves/{model_name}.tar')\n",
    "\n",
    "    previous_generator = previous_models['generator_params']\n",
    "    previous_discriminator = previous_models['discriminator_params']\n",
    "\n",
    "    current_generator = generator.state_dict()\n",
    "    current_discriminator = discriminator.state_dict()\n",
    "\n",
    "    # Updating Generator's weights\n",
    "    \n",
    "    weights = previous_generator['transconv1.weight'] # (100, 3, 4, 4)\n",
    "    weights = torch.cat([weights]*16, dim=1) # (100, 48, 4, 4)\n",
    "    zeros = torch.zeros(weights.size(0), 2, weights.size(2), weights.size(3), device=device)\n",
    "    weights = torch.cat((weights, zeros), dim=1) # (100, 50, 4, 4)\n",
    "\n",
    "    current_generator['transconv1.weight'] = weights\n",
    "\n",
    "    # Updating Discriminator's weights\n",
    "\n",
    "    weights = previous_discriminator['conv1.weight'] # (1, 3, 4, 4)\n",
    "    weights = torch.cat([weights]*100, dim=0) # (100, 3, 4, 4)\n",
    "    upsampler = torch.nn.Upsample((3,3))\n",
    "    weights = upsampler(weights) # (100, 3, 3, 3)\n",
    "    \n",
    "    current_discriminator['conv1.weight'] = weights\n",
    "\n",
    "    del weights, upsampler\n",
    "            \n",
    "    print(\"Weights Updated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    data=None,\n",
    "    generator=netG,\n",
    "    discriminator=netD,\n",
    "    epochs=50000,\n",
    "    batch_size=2048,\n",
    "    loss=nn.BCEWithLogitsLoss(),\n",
    "    optimizerD=optimizerD,\n",
    "    optimizerG=optimizerG,\n",
    "    save_point=1000,\n",
    "    checkpoint=1000,\n",
    "    model_name='default_Cocogoat',\n",
    "    keep_going=\"no\"):\n",
    "\n",
    "\n",
    "    print(\"Starting Training Loop...\")\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    if keep_going == \"no\":\n",
    "        update_weights(model_name=model_name)\n",
    "\n",
    "        start_epoch = 0\n",
    "\n",
    "    if keep_going == \"yes\":\n",
    "\n",
    "        save = torch.load(f'Saves/{model_name}.pth')\n",
    "\n",
    "        start_epoch = save['epoch']\n",
    "        discriminator.load_state_dict(save['discriminator_params'])\n",
    "        generator.load_state_dict(save['generator_params'])\n",
    "\n",
    "        print(\"Continuing from last save\")\n",
    "        \n",
    "    for epoch in range(start_epoch, epochs):\n",
    "\n",
    "        for item, image in enumerate(dataloader):\n",
    "\n",
    "            discriminator.zero_grad()\n",
    "\n",
    "            real_images = image.to(device)\n",
    "            label = torch.full((real_images.size(0),), real_label, dtype=torch.float, device=device)\n",
    "\n",
    "            # Forward pass real batch through D\n",
    "\n",
    "            output = discriminator(real_images).view(-1) # (batch_size, )\n",
    "\n",
    "            # Calculate loss on all-real batch\n",
    "\n",
    "            errD_real = loss(output, label) # Target, Input\n",
    "\n",
    "            # Calculate gradients for D in backward pass\n",
    "\n",
    "            errD_real.backward()\n",
    "\n",
    "            ## Train with all-fake batch\n",
    "\n",
    "            # Generate batch of latent vectors\n",
    "\n",
    "            noise = torch.randn((real_images.size(0), 100, 1, 1), device=device)\n",
    "\n",
    "            # Generate fake image batch with G\n",
    "\n",
    "            fake = generator(noise)\n",
    "            label.fill_(fake_label)\n",
    "\n",
    "            # Classify all fake batch with D\n",
    "\n",
    "            output = discriminator(fake.detach()).view(-1) # Using detach to avoid backpropagation through generator on this step\n",
    "\n",
    "            # Calculate D's loss on the all-fake batch\n",
    "\n",
    "            errD_fake = loss(output, label)\n",
    "\n",
    "            # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "\n",
    "            errD_fake.backward()\n",
    "\n",
    "            # Compute error of D as sum over the fake and the real batches\n",
    "\n",
    "            errD = errD_real.item() + errD_fake.item()\n",
    "\n",
    "            # Checking Discriminator's gradients to see if we're getting vanishing/exploding gradients\n",
    "\n",
    "            Dgrads_avg = torch.mean(netD.conv1.weight.grad)\n",
    "\n",
    "            # Update D\n",
    "\n",
    "            optimizerD.step()\n",
    "\n",
    "            ############################\n",
    "            # (2) Update G network\n",
    "            ###########################\n",
    "\n",
    "            generator.zero_grad()\n",
    "            label.fill_(real_label)  # fake labels are real for generator cost --> What the Discriminator predicted correctly is \"wrong\" --> backpropagation trick\n",
    "\n",
    "            # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "\n",
    "            output = discriminator(fake).view(-1)\n",
    "\n",
    "            # Calculate G's loss based on this output\n",
    "\n",
    "            errG = loss(output, label)\n",
    "\n",
    "            # Calculate gradients for G\n",
    "\n",
    "            errG.backward()\n",
    "\n",
    "            # Checking Generator's gradients to see if we're getting vanishing/exploding gradients\n",
    "\n",
    "            Ggrads_avg = torch.mean(netG.transconv1.weight.grad)\n",
    "\n",
    "            # Update G\n",
    "\n",
    "            optimizerG.step()\n",
    "\n",
    "            # Output training stats\n",
    "            if item % checkpoint == 0:\n",
    "                print(f\"{epoch}|{epochs}\")\n",
    "                print(f\"Discriminator Loss: {errD}\\tGradients Average: {Dgrads_avg}\")\n",
    "                print(f\"Generator Loss: {errG.item()}\\tGradients Average: {Ggrads_avg}\")\n",
    "\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'discriminator_params': netD.state_dict(),\n",
    "                    'generator_params': netG.state_dict(),\n",
    "                }, f\"Saves/{model_name}.tar\")\n",
    "\n",
    "                print(\"Models saved!\")\n",
    "\n",
    "        if epoch % save_point == 0:\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                saving_image = generator(noise).cpu()\n",
    "\n",
    "            saving_image = saving_image.view(saving_image.size(0), saving_image.size(2), saving_image.size(3), saving_image.size(1))\n",
    "            saving_image = saving_image.numpy()\n",
    "            saving_image = (saving_image+1.0)*0.5\n",
    "            np.save(f'Cocogoat/Image_{model_name}_{epoch}.npy', saving_image, allow_pickle=True)\n",
    "            print(f'Fake image saved!')\n",
    "            \n",
    "            _, ax = plt.subplots(2,2)\n",
    "\n",
    "            for x in range(ax.shape[0]):\n",
    "                for y in range(ax.shape[1]):\n",
    "                    ax[x,y].axis('off')\n",
    "\n",
    "            ax[0,0].imshow(saving_image[0])\n",
    "            ax[1,0].imshow(saving_image[1])\n",
    "            ax[0,1].imshow(saving_image[2])\n",
    "            ax[1,1].imshow(saving_image[3])\n",
    "\n",
    "            plt.show()\n",
    "        \n",
    "        schedulerD.step()\n",
    "        schedulerG.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(data=data, epochs=50001, batch_size=64, checkpoint=6000, save_point=5000, model_name='default_Cocogoat')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2469a70536e4d2335a2ea8907942d0699c37342a371ac185bdb5b0aa6f073890"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
